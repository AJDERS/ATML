[ENVIRONMENT]
# Number of rows for the environment.
Rows = 4

# Number of columns for the environment.
Columns = 3

# Start state.
StartState = 0,0

# Terminal state.
TerminalState = 3,2

# States with obstructions.
ObstacleStates = 1,1
                 2,2

# States with beds.
SevereObstacleStates = 2,0

[ALGORITHM]

# The step-size / learning rate, used when updating the estimated value for a
# given state, in the temporal difference learning method.
StepSize = 0.1

# Discount rate.
DiscountRate = 1

# Exploration rate, the rate at which a random action is taken.
ExplorationRate = 0.0

[REWARDS]

# The reward for each (non-winning action) action.
ActionReward = -1

# The reward for the winning tile (3, 2).
WinningReward = 0

# The reward for the bed state.
SevereObstacleReward = -10

# The reward for obstruction states.
ObstacleReward = -5